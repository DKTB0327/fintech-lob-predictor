{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPvlYvEAOxl+jKVXX3K9t4N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBRRgCk06tx7","executionInfo":{"status":"ok","timestamp":1743427997523,"user_tz":-480,"elapsed":34857,"user":{"displayName":"Kai Darren","userId":"12740578643578893856"}},"outputId":"a6d4675f-3a4c-4f4a-f263-9288fee1066f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import balanced_accuracy_score, precision_recall_fscore_support, matthews_corrcoef, cohen_kappa_score\n","from sklearn.preprocessing import LabelEncoder\n","import scipy.stats as stats\n","\n","# Load the dataset\n","dataset_path = '/content/drive/MyDrive/FYP_Dataset/LOBSTER_SampleFile_AAPL_2012-06-21_5/AAPL_2012-06-21_balanced_dataset.csv'\n","df = pd.read_csv(dataset_path)\n","\n","# Define features\n","features = ['Spread', 'Imbalance1', 'Imbalance2', 'Imbalance3', 'Imbalance4', 'Imbalance5',\n","            'AskPriceDiff1', 'AskPriceDiff2', 'AskPriceDiff3', 'AskPriceDiff4',\n","            'BidPriceDiff1', 'BidPriceDiff2', 'BidPriceDiff3', 'BidPriceDiff4',\n","            'MidPriceChange_Lag1', 'MidPriceChange_Lag5', 'MidPriceChange_Lag10',\n","            'EventCount_Type1', 'EventCount_Type2', 'EventCount_Type3', 'EventCount_Type4', 'EventCount_Type5',\n","            'AskPrice1', 'AskPrice2', 'AskPrice3', 'AskPrice4', 'AskPrice5',\n","            'BidPrice1', 'BidPrice2', 'BidPrice3', 'BidPrice4', 'BidPrice5',\n","            'AskSize1', 'AskSize2', 'AskSize3', 'AskSize4', 'AskSize5',\n","            'BidSize1', 'BidSize2', 'BidSize3', 'BidSize4', 'BidSize5',\n","            'MidPrice_Volatility_10', 'CumulativeOrderFlow', 'MidPrice_MA10',\n","            'AskSize1_MA10', 'BidSize1_MA10', 'TimeWeightedImbalance1',\n","            'EventIntensity', 'AskPrice1_Relative', 'BidPrice1_Relative',\n","            'DepthRatio', 'MidPriceChange_Cumsum10']\n","\n","# Handle NaNs\n","lagged_features = ['MidPriceChange_Lag1', 'MidPriceChange_Lag5', 'MidPriceChange_Lag10']\n","df[lagged_features] = df[lagged_features].fillna(0)\n","\n","rolling_features = ['MidPrice_Volatility_10', 'MidPrice_MA10', 'AskSize1_MA10', 'BidSize1_MA10', 'MidPriceChange_Cumsum10']\n","df[rolling_features] = df[rolling_features].fillna(method='ffill')\n","\n","df['TimeWeightedImbalance1'] = df['TimeWeightedImbalance1'].fillna(0)\n","\n","event_features = ['EventCount_Type1', 'EventCount_Type2', 'EventCount_Type3', 'EventCount_Type4', 'EventCount_Type5']\n","df[event_features] = df[event_features].fillna(0)\n","\n","# Drop remaining NaNs\n","df_cleaned = df.dropna(subset=features + ['Movement'])\n","print(\"Number of rows after handling NaNs:\", len(df_cleaned))\n","\n","# Define features and target\n","X = df_cleaned[features]\n","y = df_cleaned['Movement']\n","\n","# Encode the target labels (q_-1, q_0, q_+1) to numerical values\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n","\n","# Define a function to compute all performance metrics\n","def compute_metrics(y_true, y_pred, label_encoder):\n","    metrics = {}\n","    metrics['Balanced Accuracy'] = balanced_accuracy_score(y_true, y_pred)\n","    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n","    metrics['Weighted Precision'] = precision\n","    metrics['Weighted Recall'] = recall\n","    metrics['Weighted F1'] = f1\n","    metrics['MCC'] = matthews_corrcoef(y_true, y_pred)\n","    metrics['Cohen Kappa'] = cohen_kappa_score(y_true, y_pred)\n","\n","    # Per-class metrics\n","    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None)\n","    classes = label_encoder.classes_\n","    for i, cls in enumerate(classes):\n","        metrics[f'Precision_{cls}'] = precision[i]\n","        metrics[f'Recall_{cls}'] = recall[i]\n","        metrics[f'F1_{cls}'] = f1[i]\n","\n","    return metrics\n","\n","# 1. Random Model\n","np.random.seed(42)\n","y_pred_random = np.random.randint(0, 3, size=len(y_test))\n","metrics_random = compute_metrics(y_test, y_pred_random, label_encoder)\n","print(\"Random Model Performance:\")\n","for metric, value in metrics_random.items():\n","    print(f\"{metric}: {value:.4f}\")\n","print()\n","\n","# 2. Naive Model\n","most_frequent_class = stats.mode(y_train, keepdims=True)[0][0]\n","y_pred_naive = np.full_like(y_test, most_frequent_class)\n","metrics_naive = compute_metrics(y_test, y_pred_naive, label_encoder)\n","print(\"Naive Model Performance:\")\n","for metric, value in metrics_naive.items():\n","    print(f\"{metric}: {value:.4f}\")\n","print()\n","\n","# 3. Multinomial Logistic Regression\n","logreg = LogisticRegression(multi_class='multinomial', solver='sag', max_iter=20, tol=1e-1, random_state=42)\n","logreg.fit(X_train, y_train)\n","y_pred_logreg = logreg.predict(X_test)\n","metrics_logreg = compute_metrics(y_test, y_pred_logreg, label_encoder)\n","print(\"Multinomial Logistic Regression Performance:\")\n","for metric, value in metrics_logreg.items():\n","    print(f\"{metric}: {value:.4f}\")\n","print()\n","\n","# Summary Table of Performance Metrics\n","metrics_summary = pd.DataFrame({\n","    'Random Model': metrics_random,\n","    'Naive Model': metrics_naive,\n","    'Logistic Regression': metrics_logreg\n","})\n","print(\"\\nSummary of Performance Metrics:\")\n","print(metrics_summary.T)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pDlekhiQEGHN","executionInfo":{"status":"ok","timestamp":1743428038435,"user_tz":-480,"elapsed":40918,"user":{"displayName":"Kai Darren","userId":"12740578643578893856"}},"outputId":"ec5a3e5e-f975-40a6-b407-e61b309f27bc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-f1e1c6cb4086>:33: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df[rolling_features] = df[rolling_features].fillna(method='ffill')\n"]},{"output_type":"stream","name":"stdout","text":["Number of rows after handling NaNs: 711705\n","Random Model Performance:\n","Balanced Accuracy: 0.3349\n","Weighted Precision: 0.3349\n","Weighted Recall: 0.3349\n","Weighted F1: 0.3349\n","MCC: 0.0023\n","Cohen Kappa: 0.0023\n","Precision_q_+1: 0.3357\n","Recall_q_+1: 0.3366\n","F1_q_+1: 0.3362\n","Precision_q_-1: 0.3348\n","Recall_q_-1: 0.3359\n","F1_q_-1: 0.3353\n","Precision_q_0: 0.3342\n","Recall_q_0: 0.3322\n","F1_q_0: 0.3332\n","\n","Naive Model Performance:\n","Balanced Accuracy: 0.3333\n","Weighted Precision: 0.1106\n","Weighted Recall: 0.3326\n","Weighted F1: 0.1660\n","MCC: 0.0000\n","Cohen Kappa: 0.0000\n","Precision_q_+1: 0.0000\n","Recall_q_+1: 0.0000\n","F1_q_+1: 0.0000\n","Precision_q_-1: 0.3326\n","Recall_q_-1: 1.0000\n","F1_q_-1: 0.4992\n","Precision_q_0: 0.0000\n","Recall_q_0: 0.0000\n","F1_q_0: 0.0000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Multinomial Logistic Regression Performance:\n","Balanced Accuracy: 0.3328\n","Weighted Precision: 0.3525\n","Weighted Recall: 0.3321\n","Weighted F1: 0.1819\n","MCC: -0.0031\n","Cohen Kappa: -0.0009\n","Precision_q_+1: 0.4449\n","Recall_q_+1: 0.0138\n","F1_q_+1: 0.0267\n","Precision_q_-1: 0.3317\n","Recall_q_-1: 0.9712\n","F1_q_-1: 0.4945\n","Precision_q_0: 0.2809\n","Recall_q_0: 0.0133\n","F1_q_0: 0.0254\n","\n","\n","Summary of Performance Metrics:\n","                     Balanced Accuracy  Weighted Precision  Weighted Recall  \\\n","Random Model                  0.334887            0.334884         0.334886   \n","Naive Model                   0.333333            0.110634         0.332617   \n","Logistic Regression           0.332755            0.352530         0.332069   \n","\n","                     Weighted F1      MCC  Cohen Kappa  Precision_q_+1  \\\n","Random Model            0.334883  0.00233     0.002330        0.335706   \n","Naive Model             0.166040  0.00000     0.000000        0.000000   \n","Logistic Regression     0.181861 -0.00312    -0.000864        0.444898   \n","\n","                     Recall_q_+1   F1_q_+1  Precision_q_-1  Recall_q_-1  \\\n","Random Model            0.336646  0.336175        0.334751     0.335854   \n","Naive Model             0.000000  0.000000        0.332617     1.000000   \n","Logistic Regression     0.013771  0.026715        0.331701     0.971211   \n","\n","                      F1_q_-1  Precision_q_0  Recall_q_0    F1_q_0  \n","Random Model         0.335301       0.334195    0.332162  0.333175  \n","Naive Model          0.499193       0.000000    0.000000  0.000000  \n","Logistic Regression  0.494510       0.280944    0.013283  0.025367  \n"]}]}]}