{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOLMIAZVdIBRUyjWyvINrpx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zGWCP11-fJy6","executionInfo":{"status":"ok","timestamp":1743483555344,"user_tz":-480,"elapsed":41652,"user":{"displayName":"Kai Darren","userId":"12740578643578893856"}},"outputId":"66e57ffc-d49c-4cf0-89c8-b9bafa18c2e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHf8ey8NjcMW","executionInfo":{"status":"ok","timestamp":1743483570316,"user_tz":-480,"elapsed":14977,"user":{"displayName":"Kai Darren","userId":"12740578643578893856"}},"outputId":"b0439cd1-9eed-4ed6-bc60-594cdfeab205","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}]},{"cell_type":"code","source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.metrics import balanced_accuracy_score, precision_recall_fscore_support, matthews_corrcoef, cohen_kappa_score\n","\n","# Load the preprocessed dataset\n","dataset_path = '/content/drive/MyDrive/FYP_Dataset/LOBSTER_SampleFile_AAPL_2012-06-21_5/AAPL_2012-06-21_balanced_dataset.csv'\n","orderbook_df = pd.read_csv(dataset_path)\n","\n","# Define features\n","features = ['Spread', 'Imbalance1', 'Imbalance2', 'Imbalance3', 'Imbalance4', 'Imbalance5',\n","            'AskPriceDiff1', 'AskPriceDiff2', 'AskPriceDiff3', 'AskPriceDiff4',\n","            'BidPriceDiff1', 'BidPriceDiff2', 'BidPriceDiff3', 'BidPriceDiff4',\n","            'MidPriceChange_Lag1', 'MidPriceChange_Lag5', 'MidPriceChange_Lag10',\n","            'EventCount_Type1', 'EventCount_Type2', 'EventCount_Type3', 'EventCount_Type4', 'EventCount_Type5',\n","            'AskPrice1', 'AskPrice2', 'AskPrice3', 'AskPrice4', 'AskPrice5',\n","            'BidPrice1', 'BidPrice2', 'BidPrice3', 'BidPrice4', 'BidPrice5',\n","            'AskSize1', 'AskSize2', 'AskSize3', 'AskSize4', 'AskSize5',\n","            'BidSize1', 'BidSize2', 'BidSize3', 'BidSize4', 'BidSize5',\n","            'MidPrice_Volatility_10', 'CumulativeOrderFlow', 'MidPrice_MA10',\n","            'AskSize1_MA10', 'BidSize1_MA10', 'TimeWeightedImbalance1',\n","            'EventIntensity', 'AskPrice1_Relative', 'BidPrice1_Relative',\n","            'DepthRatio', 'MidPriceChange_Cumsum10',\n","            'MidPrice_EMA5', 'MidPrice_EMA20', 'VWAP_Imbalance',\n","            'RealizedVol_1sec', 'TimeSinceOpen']\n","\n","# Handle NaNs\n","lagged_features = ['MidPriceChange_Lag1', 'MidPriceChange_Lag5', 'MidPriceChange_Lag10']\n","orderbook_df[lagged_features] = orderbook_df[lagged_features].fillna(0)\n","\n","rolling_features = ['MidPrice_Volatility_10', 'MidPrice_MA10', 'AskSize1_MA10', 'BidSize1_MA10', 'MidPriceChange_Cumsum10', 'RealizedVol_1sec']\n","orderbook_df[rolling_features] = orderbook_df[rolling_features].ffill()\n","\n","orderbook_df['TimeWeightedImbalance1'] = orderbook_df['TimeWeightedImbalance1'].fillna(0)\n","\n","event_features = ['EventCount_Type1', 'EventCount_Type2', 'EventCount_Type3', 'EventCount_Type4', 'EventCount_Type5']\n","orderbook_df[event_features] = orderbook_df[event_features].fillna(0)\n","\n","# Drop any remaining NaNs in features and target\n","df_cleaned = orderbook_df.dropna(subset=features + ['Movement'])\n","print(\"Number of rows after handling NaNs:\", len(df_cleaned))\n","\n","# Define features and target\n","X = df_cleaned[features]\n","y = df_cleaned['Movement']\n","\n","# Encode the target labels\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n","\n","# Scale the features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Define the compute_metrics function\n","def compute_metrics(y_true, y_pred, label_encoder, model_name=\"Model\"):\n","    metrics = {}\n","    metrics['Balanced Accuracy'] = balanced_accuracy_score(y_true, y_pred)\n","    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n","    metrics['Weighted Precision'] = precision\n","    metrics['Weighted Recall'] = recall\n","    metrics['Weighted F1'] = f1\n","    metrics['MCC'] = matthews_corrcoef(y_true, y_pred)\n","    metrics['Cohen Kappa'] = cohen_kappa_score(y_true, y_pred)\n","\n","    # Per-class metrics\n","    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None)\n","    classes = label_encoder.classes_\n","    for i, cls in enumerate(classes):\n","        metrics[f'Precision_{cls}'] = precision[i]\n","        metrics[f'Recall_{cls}'] = recall[i]\n","        metrics[f'F1_{cls}'] = f1[i]\n","\n","    # Print metrics\n","    print(f\"{model_name} Performance:\")\n","    for metric, value in metrics.items():\n","        print(f\"{metric}: {value:.4f}\")\n","    print()\n","\n","    return metrics\n","\n","# Initialize the all_metrics dictionary\n","all_metrics = {}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rF24RmG933Rq","executionInfo":{"status":"ok","timestamp":1743483612547,"user_tz":-480,"elapsed":42219,"user":{"displayName":"Kai Darren","userId":"12740578643578893856"}},"outputId":"d402fb47-d195-4c4a-f645-b97c9440b857"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of rows after handling NaNs: 711705\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","import numpy as np\n","\n","# Select top features\n","top_features = [\n","    'MidPriceChange_Cumsum10', 'RealizedVol_1sec', 'MidPrice_Volatility_10',\n","    'MidPriceChange_Lag1', 'EventCount_Type4', 'TimeWeightedImbalance1',\n","    'AskPriceDiff2', 'EventCount_Type3', 'EventCount_Type1', 'AskPriceDiff1'\n","]\n","\n","# Subset and scale data\n","X_top = df_cleaned[top_features]\n","y = label_encoder.fit_transform(df_cleaned['Movement'])\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X_top)\n","\n","# Reshape into sequences\n","timesteps = 10\n","X_sequences = []\n","y_sequences = []\n","for i in range(len(X_scaled) - timesteps):\n","    X_sequences.append(X_scaled[i:i+timesteps])\n","    y_sequences.append(y[i+timesteps])\n","X_sequences = np.array(X_sequences)\n","y_sequences = np.array(y_sequences)\n","\n","# Split data\n","X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42)\n","\n","# Define LSTM model\n","model = Sequential([\n","    LSTM(64, activation='tanh', input_shape=(timesteps, len(top_features))),\n","    Dropout(0.2),\n","    Dense(32, activation='relu'),\n","    Dense(3, activation='softmax')\n","])\n","\n","# Compile\n","model.compile(optimizer=Adam(learning_rate=0.001),\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n","\n","# Train\n","model.fit(X_train_seq, y_train_seq,\n","          epochs=50,\n","          batch_size=128,\n","          validation_split=0.2,\n","          callbacks=[early_stopping, reduce_lr],\n","          verbose=1)\n","\n","# Predict and evaluate\n","y_pred = np.argmax(model.predict(X_test_seq), axis=1)\n","metrics = compute_metrics(y_test_seq, y_pred, label_encoder, \"LSTM-Simplified\")\n","all_metrics['LSTM-Simplified'] = metrics\n","\n","# Save model\n","model.save('/content/drive/MyDrive/FYP_Dataset/LOBSTER_SampleFile_AAPL_2012-06-21_5/lstm_simplified.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"Jgk3XfCYiXxB","executionInfo":{"status":"error","timestamp":1744731626042,"user_tz":-480,"elapsed":16996,"user":{"displayName":"Kai Darren","userId":"12740578643578893856"}},"outputId":"8bea1ebc-a78e-4830-e9a1-f4a60fb303d3"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_cleaned' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-89c747f9ffba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Subset and scale data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mX_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Movement'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_cleaned' is not defined"]}]}]}